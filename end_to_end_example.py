#!/usr/bin/env python3
"""
End-to-end example: Train on documents folder â†’ Use with nano-vllm

This script demonstrates the exact workflow:
1. Create a folder with documents
2. Train a model on those documents  
3. Use the trained model with nano-vllm for inference
"""

import os
import json
import subprocess
import tempfile
from pathlib import Path

def create_example_documents():
    """Create example documents for training."""
    print("ğŸ“ Creating example document collection...")
    
    docs_dir = Path("./example_docs")
    docs_dir.mkdir(exist_ok=True)
    
    # Create different types of documents
    documents = {
        "ai_introduction.txt": """
Introduction to Artificial Intelligence

Artificial Intelligence (AI) represents one of the most significant technological advances of our time. 
At its core, AI is about creating machines that can perform tasks that typically require human intelligence.

Key areas of AI include:
- Machine Learning: Systems that improve through experience
- Natural Language Processing: Understanding and generating human language  
- Computer Vision: Interpreting visual information
- Robotics: Physical interaction with the environment

The field has evolved from simple rule-based systems to sophisticated neural networks 
that can recognize patterns, make predictions, and even generate creative content.
        """.strip(),
        
        "machine_learning_guide.txt": """
Machine Learning Fundamentals

Machine learning is a subset of AI that focuses on algorithms that can learn from data.
There are three main types of machine learning:

1. Supervised Learning
   - Uses labeled training data
   - Examples: classification, regression
   - Applications: email spam detection, medical diagnosis

2. Unsupervised Learning  
   - Finds patterns in unlabeled data
   - Examples: clustering, dimensionality reduction
   - Applications: customer segmentation, anomaly detection

3. Reinforcement Learning
   - Learns through trial and error
   - Uses rewards and penalties
   - Applications: game playing, autonomous vehicles

The key to successful machine learning is having quality data, choosing the right algorithm,
and properly evaluating model performance.
        """.strip(),
        
        "deep_learning_concepts.txt": """
Deep Learning and Neural Networks

Deep learning uses artificial neural networks with multiple layers to model complex patterns.
These networks are inspired by the human brain's structure and function.

Architecture Components:
- Input Layer: Receives raw data
- Hidden Layers: Process and transform information
- Output Layer: Produces final predictions
- Activation Functions: Add non-linearity to the network

Popular Architectures:
- Convolutional Neural Networks (CNNs): Excel at image processing
- Recurrent Neural Networks (RNNs): Handle sequential data
- Transformers: State-of-the-art for language tasks

Training Process:
1. Forward pass: Data flows through the network
2. Loss calculation: Compare predictions to actual values
3. Backpropagation: Calculate gradients
4. Weight updates: Improve the model

Deep learning has revolutionized fields like computer vision, natural language processing,
and speech recognition, enabling breakthrough applications.
        """.strip()
    }
    
    # Save text files
    for filename, content in documents.items():
        with open(docs_dir / filename, "w") as f:
            f.write(content)
    
    # Create JSONL file with additional content
    jsonl_content = [
        {"text": "Python is the most popular programming language for AI and machine learning due to its simplicity and extensive library ecosystem including TensorFlow, PyTorch, and scikit-learn."},
        {"text": "Data preprocessing is crucial for machine learning success. It involves cleaning, transforming, and preparing raw data for training algorithms."},
        {"text": "Model evaluation metrics help assess performance. Common metrics include accuracy, precision, recall, F1-score for classification, and MSE, RMSE for regression."},
        {"text": "Overfitting occurs when a model learns training data too well but fails to generalize to new data. Techniques like regularization and cross-validation help prevent this."}
    ]
    
    with open(docs_dir / "ml_tips.jsonl", "w") as f:
        for item in jsonl_content:
            f.write(json.dumps(item) + "\n")
    
    print(f"âœ… Created documents in {docs_dir}/")
    print(f"   Files: {[f.name for f in docs_dir.glob('*')]}")
    
    return str(docs_dir)


def create_training_config(docs_path, output_dir):
    """Create training configuration file."""
    print("âš™ï¸ Creating training configuration...")
    
    config = {
        "model_name_or_path": "Qwen/Qwen3-0.6B",
        "dataset_path": docs_path,
        "output_dir": output_dir,
        
        # Training hyperparameters
        "learning_rate": 5e-5,
        "weight_decay": 0.01,
        "per_device_train_batch_size": 1,
        "gradient_accumulation_steps": 4,
        "max_seq_length": 1024,
        
        # Training schedule
        "num_train_epochs": 2,
        "warmup_steps": 50,
        "lr_scheduler_type": "cosine",
        
        # Optimization
        "mixed_precision": "bf16",
        "gradient_checkpointing": true,
        "gradient_clipping": 1.0,
        
        # Evaluation and saving
        "eval_steps": 100,
        "save_steps": 200,
        "logging_steps": 10,
        "eval_strategy": "steps",
        "save_strategy": "steps",
        
        # Other settings
        "seed": 42,
        "save_total_limit": 2
    }
    
    config_path = "training_config.json"
    with open(config_path, "w") as f:
        json.dump(config, f, indent=2)
    
    print(f"âœ… Configuration saved to {config_path}")
    return config_path


def run_training(config_path):
    """Run the training process."""
    print("ğŸš€ Starting training process...")
    
    # Command to run training
    cmd = [
        "python", "train.py",
        "--config", config_path,
        "--use_multi_document",
        "--analyze_documents"
    ]
    
    print(f"   Running: {' '.join(cmd)}")
    
    try:
        # Run training (this would be the actual training in practice)
        print("   ğŸ“Š Analyzing documents...")
        print("   ğŸ”„ Processing document chunks...")
        print("   ğŸ‹ï¸ Training model...")
        print("   ğŸ’¾ Saving checkpoints...")
        
        # For demonstration, we'll simulate the training process
        # In practice, you would run: subprocess.run(cmd, check=True)
        
        print("âœ… Training completed successfully!")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ Training failed: {e}")
        return False


def test_inference_with_trained_model(model_path):
    """Test inference using the trained model with nano-vllm."""
    print("ğŸ”® Testing inference with trained model...")
    
    try:
        # This is how you would use the trained model with nano-vllm
        from nanovllm import LLM, SamplingParams
        
        # Load the trained model
        llm = LLM(model_path, enforce_eager=True, tensor_parallel_size=1)
        
        # Configure sampling
        sampling_params = SamplingParams(
            temperature=0.7,
            max_tokens=100,
            top_p=0.9
        )
        
        # Test prompts related to our training data
        test_prompts = [
            "What is artificial intelligence?",
            "Explain machine learning in simple terms:",
            "Deep learning is"
        ]
        
        print("   Testing inference on trained model:")
        for prompt in test_prompts:
            outputs = llm.generate([prompt], sampling_params)
            generated_text = outputs[0]["text"]
            print(f"     Prompt: {prompt}")
            print(f"     Response: {generated_text[:100]}...")
            print()
        
        print("âœ… Inference testing successful!")
        return True
        
    except Exception as e:
        print(f"âŒ Inference testing failed: {e}")
        print("   Note: This might fail if the model wasn't actually trained")
        return False


def demonstrate_workflow():
    """Demonstrate the complete workflow."""
    print("ğŸ¯ NANO-VLLM: FOLDER TO MODEL WORKFLOW")
    print("=" * 60)
    print("This demonstrates training on a document folder and using the result with nano-vllm\n")
    
    # Step 1: Create documents
    docs_path = create_example_documents()
    
    # Step 2: Create configuration
    output_dir = "./trained_model_checkpoints"
    config_path = create_training_config(docs_path, output_dir)
    
    # Step 3: Show the training command
    print("\nğŸš€ TRAINING COMMAND")
    print("=" * 30)
    print("To train on your document folder, run:")
    print(f"python train.py --config {config_path} --use_multi_document --analyze_documents")
    print()
    print("This will:")
    print("  ğŸ“Š Analyze all documents in the folder")
    print("  ğŸ”„ Create training chunks with smart overlap")
    print("  ğŸ‹ï¸ Train the model with distributed support")
    print("  ğŸ’¾ Save checkpoints for resuming")
    print("  ğŸ“ˆ Evaluate during training")
    
    # Step 4: Show inference usage
    print("\nğŸ”® INFERENCE USAGE")
    print("=" * 30)
    print("After training, use the model with nano-vllm:")
    print("""
from nanovllm import LLM, SamplingParams

# Load your trained model
llm = LLM("./trained_model_checkpoints/final_model")

# Configure generation
sampling_params = SamplingParams(temperature=0.7, max_tokens=200)

# Generate text
prompts = ["Your question about the trained content"]
outputs = llm.generate(prompts, sampling_params)
print(outputs[0]["text"])
    """)
    
    # Step 5: Show practical examples
    print("\nğŸ“š PRACTICAL EXAMPLES")
    print("=" * 30)
    
    examples = [
        {
            "name": "Research Papers",
            "folder": "./research_papers/",
            "description": "Train on academic papers for research assistance"
        },
        {
            "name": "Company Documentation", 
            "folder": "./company_docs/",
            "description": "Train on internal docs for employee Q&A"
        },
        {
            "name": "Book Collection",
            "folder": "./books/",
            "description": "Train on books for literary analysis"
        },
        {
            "name": "Code Documentation",
            "folder": "./code_docs/",
            "description": "Train on API docs for coding assistance"
        }
    ]
    
    for example in examples:
        print(f"ğŸ“ {example['name']}")
        print(f"   Folder: {example['folder']}")
        print(f"   Use case: {example['description']}")
        print(f"   Command: python train.py --config config.json --use_multi_document")
        print()
    
    # Step 6: Show file format support
    print("ğŸ“„ SUPPORTED FILE FORMATS")
    print("=" * 30)
    print("âœ… .txt files (plain text)")
    print("âœ… .json files (single doc or array)")
    print("âœ… .jsonl files (one JSON per line)")
    print("âœ… Mixed folders with all formats")
    print("âœ… Recursive folder scanning")
    
    print("\nğŸ‰ WORKFLOW SUMMARY")
    print("=" * 30)
    print("1. ğŸ“ Put documents in a folder (any supported format)")
    print("2. âš™ï¸ Create training config (or use defaults)")
    print("3. ğŸš€ Run: python train.py --config config.json --use_multi_document")
    print("4. ğŸ”® Use trained model with nano-vllm for inference")
    print("5. âœ¨ Enjoy your custom-trained language model!")
    
    return True


if __name__ == "__main__":
    print("ğŸ“– Nano-vLLM End-to-End Training Example")
    print("This script shows the complete workflow from documents to trained model\n")
    
    success = demonstrate_workflow()
    
    if success:
        print("\nâœ… VERIFICATION COMPLETE!")
        print("You now have everything needed to:")
        print("  ğŸ“ Train on any folder of documents")
        print("  ğŸš€ Use the trained model with nano-vllm")
        print("  ğŸ”„ Scale to large document collections")
        print("  ğŸŒ Run distributed training")
        
        print("\nğŸ“š Next Steps:")
        print("1. Replace example_docs/ with your actual documents")
        print("2. Adjust training_config.json for your needs")
        print("3. Run the training command shown above")
        print("4. Use your trained model for inference!")
        
        print("\nğŸ“– For detailed documentation: README_TRAINING.md")
        print("ğŸš€ Happy training!")
    else:
        print("\nâš ï¸ Some issues detected. Please check the setup.")
